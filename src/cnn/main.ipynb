{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RVoZA8DUkDLg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 1us/step\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.src.datasets import cifar10\n",
        "from keras.api.models import Sequential\n",
        "from keras.api.layers import Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense, Input\n",
        "from keras.api.optimizers import Adam\n",
        "from keras.api.losses import SparseCategoricalCrossentropy\n",
        "from sklearn.metrics import f1_score\n",
        "from keras.api.utils import to_categorical\n",
        "from keras.api.models import load_model\n",
        "\n",
        "(x_full_train, y_full_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_full_train = x_full_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "split_index = int(0.8 * len(x_full_train))\n",
        "x_train, x_val = x_full_train[:split_index], x_full_train[split_index:]\n",
        "y_train, y_val = y_full_train[:split_index], y_full_train[split_index:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lNSAuCDjkICz",
        "outputId": "e7b432cf-c501-4237-b448-1cc3b4c71f39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Eksperimen: CNN_Model ---\n",
            "Epoch 1/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 148ms/step - accuracy: 0.3484 - loss: 1.7815 - val_accuracy: 0.6027 - val_loss: 1.1265\n",
            "Epoch 2/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 139ms/step - accuracy: 0.6351 - loss: 1.0248 - val_accuracy: 0.6830 - val_loss: 0.8983\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 113ms/step - accuracy: 0.7304 - loss: 0.7578 - val_accuracy: 0.7164 - val_loss: 0.8008\n",
            "Epoch 4/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 120ms/step - accuracy: 0.7917 - loss: 0.5845 - val_accuracy: 0.7435 - val_loss: 0.7604\n",
            "Epoch 5/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 129ms/step - accuracy: 0.8527 - loss: 0.4150 - val_accuracy: 0.7433 - val_loss: 0.8244\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 133ms/step - accuracy: 0.8992 - loss: 0.2874 - val_accuracy: 0.7458 - val_loss: 0.8856\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 135ms/step - accuracy: 0.9309 - loss: 0.2006 - val_accuracy: 0.7417 - val_loss: 1.0016\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.9533 - loss: 0.1386"
          ]
        }
      ],
      "source": [
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "def build_cnn_scratch(num_conv_layers, filters_per_layer, kernel_sizes, pooling_type='max'):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=x_train.shape[1:]))\n",
        "    for i in range(num_conv_layers):\n",
        "        model.add(Conv2D(filters=filters_per_layer[i], kernel_size=kernel_sizes[i],\n",
        "                         activation='relu', padding='same'))\n",
        "        if pooling_type == 'max':\n",
        "            model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "        else:\n",
        "            model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(500, activation='relu'))\n",
        "    model.add(Dense(250, activation='relu'))\n",
        "    model.add(Dense(20, activation='softmax'))\n",
        "    model.compile(\n",
        "        optimizer=Adam(),\n",
        "        loss=SparseCategoricalCrossentropy(),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def run_cnn_scratch(param: dict, epochs=20, batch_size=64):\n",
        "    results = {}\n",
        "    name = param['name']\n",
        "    print(f\"\\n--- Eksperimen: {name} ---\")\n",
        "    model = build_cnn_scratch(\n",
        "        param['num_conv_layers'],\n",
        "        param['filters_per_layer'],\n",
        "        param['kernel_sizes'],\n",
        "        param['pooling_type']\n",
        "    )\n",
        "    history = model.fit(\n",
        "        x_train, y_train,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        validation_data=(x_val, y_val),\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    model_path = f\"models/{name}.keras\"\n",
        "    model.save(model_path)\n",
        "    print(f\"Model disimpan di: {model_path}\")\n",
        "\n",
        "    y_pred = np.argmax(model.predict(x_test), axis=1)\n",
        "    y_true = y_test.flatten()\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    print(f\"Macro F1-score untuk {name}: {f1:.4f}\")\n",
        "    results[name] = {'history':history.history, 'f1_score':f1}\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(history.history['loss'], label='train_loss')\n",
        "    plt.plot(history.history['val_loss'], label='val_loss')\n",
        "    plt.title(f\"Loss Curves for {name}\")\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    return results\n",
        "\n",
        "param = {'name':'CNN_Model', 'num_conv_layers':3, 'filters_per_layer':[128,256,512], 'kernel_sizes':[3,3,3], 'pooling_type':'max'}\n",
        "saved_model = run_cnn_scratch(param, epochs=20, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8x0imoZy8Uh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step\n",
            "Scratch Macro F1: 0.7237685392945128\n",
            "Keras Macro F1: 0.7237685392945128\n"
          ]
        }
      ],
      "source": [
        "y_train_scr = to_categorical(y_train, 10)\n",
        "y_val_scr = to_categorical(y_val, 10)\n",
        "y_test_scr = to_categorical(y_test, 10)\n",
        "y_test_labels = np.argmax(y_test_scr, axis=1)\n",
        "\n",
        "class Conv2D_scr:\n",
        "    def __init__(self, W, b, stride=1, padding='same'):\n",
        "        self.W = W\n",
        "        self.b = b\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "\n",
        "    def forward(self, x):\n",
        "        fh, fw, _, out_ch = self.W.shape\n",
        "        batch, h, w, _ = x.shape\n",
        "        if self.padding == 'same':\n",
        "            pad_h = (fh - 1) // 2\n",
        "            pad_w = (fw - 1) // 2\n",
        "            x = np.pad(x, ((0,0),(pad_h,pad_h),(pad_w,pad_w),(0,0)), mode='constant')\n",
        "        out_h = (h + 2*pad_h - fh) // self.stride + 1\n",
        "        out_w = (w + 2*pad_w - fw) // self.stride + 1\n",
        "        out = np.zeros((batch, out_h, out_w, out_ch), dtype=np.float32)\n",
        "        for i in range(out_h):\n",
        "            for j in range(out_w):\n",
        "                hs, he = i * self.stride, i * self.stride + fh\n",
        "                ws, we = j * self.stride, j * self.stride + fw\n",
        "                patch = x[:, hs:he, ws:we, :]\n",
        "                for k in range(out_ch):\n",
        "                    out[:, i, j, k] = np.sum(patch * self.W[..., k], axis=(1,2,3)) + self.b[k]\n",
        "        return out\n",
        "\n",
        "class ReLU_scr:\n",
        "    def forward(self, x):\n",
        "      return np.maximum(0, x)\n",
        "\n",
        "class MaxPool2D_scr:\n",
        "    def __init__(self, pool_size=(2,2), stride=2):\n",
        "        self.ph, self.pw = pool_size\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch, h, w, ch = x.shape\n",
        "        out_h = (h - self.ph) // self.stride + 1\n",
        "        out_w = (w - self.pw) // self.stride + 1\n",
        "        out = np.zeros((batch, out_h, out_w, ch), dtype=np.float32)\n",
        "        for i in range(out_h):\n",
        "            for j in range(out_w):\n",
        "                hs, he = i * self.stride, i * self.stride+self.ph\n",
        "                ws, we = j * self.stride, j * self.stride+self.pw\n",
        "                patch = x[:, hs:he, ws:we, :]\n",
        "                out[:, i, j, :] = np.max(patch, axis=(1,2))\n",
        "        return out\n",
        "\n",
        "class AvgPool2D_scr:\n",
        "    def __init__(self, pool_size=(2,2), stride=2):\n",
        "        self.ph, self.pw = pool_size\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch, h, w, ch = x.shape\n",
        "        out_h = (h - self.ph) // self.stride + 1\n",
        "        out_w = (w - self.pw) // self.stride + 1\n",
        "        out = np.zeros((batch, out_h, out_w, ch), dtype=np.float32)\n",
        "        for i in range(out_h):\n",
        "            for j in range(out_w):\n",
        "                hs, he = i * self.stride, i * self.stride + self.ph\n",
        "                ws, we = j * self.stride, j * self.stride + self.pw\n",
        "                patch = x[:, hs:he, ws:we, :]\n",
        "                out[:, i, j, :] = np.mean(patch, axis=(1,2))\n",
        "        return out\n",
        "\n",
        "class Flatten_scr:\n",
        "    def forward(self, x):\n",
        "      return x.reshape(x.shape[0], -1)\n",
        "\n",
        "class Dense_scr:\n",
        "    def __init__(self, W, b):\n",
        "        self.W, self.b = W, b\n",
        "\n",
        "    def forward(self, x):\n",
        "      return x.dot(self.W) + self.b\n",
        "\n",
        "class Softmax_scr:\n",
        "    def forward(self, x):\n",
        "        e = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "        return e / np.sum(e, axis=1, keepdims=True)\n",
        "\n",
        "model_path = ('models/CNN_Model.keras')\n",
        "keras_model = load_model(model_path)\n",
        "\n",
        "layers = []\n",
        "for layer in keras_model.layers:\n",
        "    if isinstance(layer, Conv2D):\n",
        "        W, b = layer.get_weights()\n",
        "        layers.append(Conv2D_scr(W, b, stride=layer.strides[0], padding=layer.padding))\n",
        "        layers.append(ReLU_scr())\n",
        "    elif isinstance(layer, MaxPooling2D):\n",
        "        layers.append(MaxPool2D_scr(pool_size=layer.pool_size, stride=layer.strides[0]))\n",
        "    elif isinstance(layer, Flatten):\n",
        "        layers.append(Flatten_scr())\n",
        "    elif isinstance(layer, Dense):\n",
        "        W, b = layer.get_weights()\n",
        "        layers.append(Dense_scr(W, b))\n",
        "        act = layer.activation.__name__\n",
        "        if act == 'softmax':\n",
        "          layers.append(Softmax_scr())\n",
        "        elif act == 'relu':\n",
        "          layers.append(ReLU_scr())\n",
        "\n",
        "def scratch_predict(x):\n",
        "    out = x.copy()\n",
        "    for l in layers:\n",
        "        out = l.forward(out)\n",
        "    return out\n",
        "\n",
        "scratch_out = scratch_predict(x_test)\n",
        "scratch_pred = np.argmax(scratch_out, axis=1)\n",
        "\n",
        "keras_out = keras_model.predict(x_test)\n",
        "keras_pred = np.argmax(keras_out, axis=1)\n",
        "\n",
        "print('Scratch Macro F1:', f1_score(y_test_labels, scratch_pred, average='macro'))\n",
        "print('Keras Macro F1:', f1_score(y_test_labels, keras_pred, average='macro'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
